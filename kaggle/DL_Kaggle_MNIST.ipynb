{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport tensorflow as tf\nimport numpy as np\nimport struct\nimport matplotlib.pyplot as plt\npath = '/kaggle/input/coic/train-images-idx3-ubyte'\nwith open(path,'rb') as f1:\n    buf1 = f1.read() \nimage_index = 0\nimage_index += struct.calcsize('>IIII')\ntemp = struct.unpack_from('>784B', buf1, image_index) \n# '>784B'的意思就是用大端法读取784( 28*28 )个unsigned byte\nim = np.reshape(temp,(28,28))\nplt.imshow(im , cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####  https://www.jianshu.com/p/84f72791806f\nimport numpy as np\nimport struct\nimport matplotlib.pyplot as plt\n\ntrain_images_idx3_ubyte_file = '/kaggle/input/coic/train-images-idx3-ubyte'\ntrain_labels_idx1_ubyte_file = '/kaggle/input/coic/train-labels-idx1-ubyte'\n\ntest_images_idx3_ubyte_file = '/kaggle/input/coic/test-images-idx3-ubyte'\ntest_labels_idx1_ubyte_file = '/kaggle/input/coic/test-labels-idx1-ubyte'\nfinal_test_idx3_ubyte_file = '/kaggle/input/coic/final-test-images-idx3-ubyte'\n\n\n\ndef decode_idx3_ubyte(idx3_ubyte_file):\n    \n    bin_data = open(idx3_ubyte_file, 'rb').read()\n\n    offset = 0\n    fmt_header = '>iiii'\n    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n\n    image_size = num_rows * num_cols\n    offset += struct.calcsize(fmt_header)\n    fmt_image = '>' + str(image_size) + 'B'\n    images = np.empty((num_images, num_rows, num_cols))\n    for i in range(num_images):\n        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n        offset += struct.calcsize(fmt_image)\n    return images\n\n\ndef decode_idx1_ubyte(idx1_ubyte_file):\n\n    bin_data = open(idx1_ubyte_file, 'rb').read()\n\n\n    offset = 0\n    fmt_header = '>ii'\n    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n\n    \n    offset += struct.calcsize(fmt_header)\n    fmt_image = '>B'\n    labels = np.empty(num_images)\n    for i in range(num_images):\n        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n        offset += struct.calcsize(fmt_image)\n    return labels\n\n\ndef load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n    \"\"\"\n    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000803(2051) magic number\n    0004     32 bit integer  60000            number of images\n    0008     32 bit integer  28               number of rows\n    0012     32 bit integer  28               number of columns\n    0016     unsigned byte   ??               pixel\n    0017     unsigned byte   ??               pixel\n    ........\n    xxxx     unsigned byte   ??               pixel\n    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n\n    :param idx_ubyte_file: idx文件路径\n    :return: n*row*col维np.array对象，n为图片数量\n    \"\"\"\n    return decode_idx3_ubyte(idx_ubyte_file)\n\n\ndef load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n    \"\"\"\n    TRAINING SET LABEL FILE (train-labels-idx1-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n    0004     32 bit integer  60000            number of items\n    0008     unsigned byte   ??               label\n    0009     unsigned byte   ??               label\n    ........\n    xxxx     unsigned byte   ??               label\n    The labels values are 0 to 9.\n\n    :param idx_ubyte_file: idx文件路径\n    :return: n*1维np.array对象，n为图片数量\n    \"\"\"\n    return decode_idx1_ubyte(idx_ubyte_file)\n\n\ndef load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n    \"\"\"\n    TEST SET IMAGE FILE (t10k-images-idx3-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000803(2051) magic number\n    0004     32 bit integer  10000            number of images\n    0008     32 bit integer  28               number of rows\n    0012     32 bit integer  28               number of columns\n    0016     unsigned byte   ??               pixel\n    0017     unsigned byte   ??               pixel\n    ........\n    xxxx     unsigned byte   ??               pixel\n    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n\n    :param idx_ubyte_file: idx文件路径\n    :return: n*row*col维np.array对象，n为图片数量\n    \"\"\"\n    return decode_idx3_ubyte(idx_ubyte_file)\n\n\ndef load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n    \"\"\"\n    TEST SET LABEL FILE (t10k-labels-idx1-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n    0004     32 bit integer  10000            number of items\n    0008     unsigned byte   ??               label\n    0009     unsigned byte   ??               label\n    ........\n    xxxx     unsigned byte   ??               label\n    The labels values are 0 to 9.\n\n    :param idx_ubyte_file: idx文件路径\n    :return: n*1维np.array对象，n为图片数量\n    \"\"\"\n    return decode_idx1_ubyte(idx_ubyte_file)\n\n\n\n\ntrain_images = load_train_images()\ntrain_labels = load_train_labels()\ntest_images = load_test_images()\ntest_labels = load_test_labels()\nfinal_test_images = load_test_images(final_test_idx3_ubyte_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**讓label變成one-hot (ex: 1 ->[0,1,...,0,0])**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(train_labels)\ny_test = tf.keras.utils.to_categorical(test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalize**\n本來image都是介於0~255 透過這動作變成-1~1之間"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = (train_images-127.5)/127.5\nx_test = (test_images-127.5)/127.5\nfinal_x = (final_test_images-127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#不同的NN需要不同格式輸入\n\"\"\"\"x_train = x_train.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)\nfinal_x = final_x.reshape(-1, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train shape after splitting : {}\".format(x_train.shape))\nprint(\"Shape of input images for Validation after splitting : {}\".format(x_test.shape))\nprint(\"y_label shape after splitting : {}\".format(y_train.shape))\nprint(\"Shape of output labels for Validation after splitting : {}\".format(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = (28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dense(10, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\"#compile the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr = 0.001), metrics = ['accuracy'])\nhistory = model.fit(x_train, y_train, \n                    epochs = 25, batch_size = 32, \n                    validation_data = (x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define model and train**\nopt=adam\nloss=crossentropy\nepoch=20"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(1000, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(1000, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(10, activation='softmax')    \n])\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) #learning_rate mostly adjust *10 or /10\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n#model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Use the trained model to predict on fianl_test images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_y = model.predict(final_x)\nfinal_pred = np.argmax(model.predict(final_x), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Write the prediction in .csv file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\n# 開啟輸出的 CSV 檔案\nwith open('output.csv', 'w', newline='') as csvfile:\n  # 建立 CSV 檔寫入器\n    writer = csv.writer(csvfile)\n\n  # 寫入一列資料\n    writer.writerow(['ID', 'Class'])\n    for i,_ in enumerate(final_pred):\n         writer.writerow([i+1,final_pred[i] ])\n\n  # 寫入另外幾列資料","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**另一種方法輸出.csv檔**"},{"metadata":{"trusted":true},"cell_type":"code","source":"id=[]\nfor i,_ in enumerate(final_pred):\n    id.append(i+1)\n### final_test has 4563 pictures\nprint(id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'ID' : id,\n    'Class' : final_pred\n})\n\nresults.to_csv('predict.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}